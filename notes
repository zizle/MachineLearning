特征工程三大知识点：1. 特征抽取；2.特征预处理； 3.特征降维

数据类型： 1.离散型； 2. 连续型


机器学习的算法分类：
    1. 监督学习： 特征值+目标值都有
        分类：目标值是离散型数据
            k-邻近算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络

        回归：目标值连续性数据
            线性回归、岭回归

        标注：隐马尔可夫模型
    2. 无监督学习： 只有特征值

机器学习开发过程：
    数据---> 建立模型(明确做什么)--->数据基本处理 ---> 特征工程(重点) ---> 算法分析 ---> 模型评估(判定效果) ---> 上线使用

转换器：特征工程的API
估计器：算法的API


k-近邻算法：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别
        欧式距离: (a1-b1)+(a2-b2)+(a3-b3)...各个平方和再开根号
        1. 需要做标准化处理
        2. API：sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, algorithm='auto)
                k值:n_neighbors取很小容易受异常点影响， 取很大容易受类别影响波动
        优点:简单，易于理解，无需估计参数，无需训练
        缺点：懒惰算法，对样本分类时计算量很大，内存开销大
             必须制定k值，取值不当，分类精度不能保证
        适用: 小数据场景，几千~几万的样本